---
title: "Proyecto Grupal - Herramientas de Ciencias de Datos II"
author: 
  - Estudiantes
  - Luis Fernando Amey Apuy - C20470
  - Javier Hernández Navarro - C13674
  - Anthony Mauricio Jiménez Navarro - C24067
date: "2024-05-13"
output: 
  rmdformats::downcute:
    default_style: "dark"
    downcute_theme: "chaos"
---
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

# Importación librerias
```{r, warning=FALSE, message=FALSE}
library(readr)
library(tidyverse)
library(lubridate)
library(reticulate)

```

```{r}
scrap <- function(name){
  # setear la carpeta de la data
  setwd("data")
  
  # buscar el archivo
  ruta <- paste(name, ".txt", sep = '')
  texto <- read_file(ruta)

  # remover, si es posible, los \r, y trabajar en \n
  texto <- str_replace_all(texto, "\r", "")
  texto <- strsplit(texto, '\n')[[1]]
  
  # separar horas y mensaje
  temp <- str_split_fixed(texto, "\\] ", 2)  

  # realizar el dataframe con los datos iniciales
  datos <- data.frame(hora = numeric(length(texto)))
  datos$hora <- temp[,1]
  datos$autor <- numeric(length(texto))
  datos$mensaje <- temp[,2]
  
  # Dividir entre autor y mensaje
  temp <- str_split_fixed(datos$mensaje, ": ", 2)
  datos$autor <- temp[,1]
  datos$mensaje <- temp[,2]
  
  # Sacar los índices de los enters en línea
  indices <- as.numeric(rownames(datos[!grepl("\\[", datos$hora),]))
  
  # Operar estas líneas
  for (i in indices){
    datos$mensaje[i] <- datos$hora[i]
    datos[i,1:2] <- datos[i-1,1:2]
  }
  datos$mensaje <- as.character(datos$mensaje)
  
  # Eliminar el corchete extra
  datos$hora <- gsub("\\[", "", datos$hora)
  
  # Dividir en días y horas
  datos <- datos %>% separate(hora, into = c("dia", "hora"), sep = ", ")
  
  # Formato lubridate
  datos$dia <- as_date(dmy(datos$dia))
  
  # En caso de PM, o p. m. AM lo ignora
  datos<- datos %>% mutate(pm = grepl("[pP]", datos$hora))
  datos$hora <- str_replace_all(datos$hora, "p\\.\\s*m\\.", "")
  datos$hora <- str_replace_all(datos$hora, "a\\.\\s*m\\.", "")  
  
  # Moverse a hms de 24 horas
  datos$hora <- hms(datos$hora)
  datos$hora <- datos$hora + hours(datos$pm*12)
  
  # Quitar la columna extra
  datos <- datos %>% select(-pm)
  return(datos)
}
```

```{r, warning=FALSE}
gen <- scrap("gen")
```

# Funciones extra
```{r}
spammer <- function(df){
  num <- df%>% count(autor) %>% arrange(desc(n))
  return(num)
}

dia_concurrido <- function(df){
    num <- df%>% count(dia) %>% arrange(desc(n))
  return(num)
}

hora_concurrida <- function(df){
  df$hora <- hour(df$hora)
  num <- df %>% count(hora) %>% arrange(desc(n))
  return(num[1,1])
}

streak_dias <- function(df){
  num <- unique(df$dia)
  dif <- num[1:length(num)-1] - num[2:length(num)]
  df <- data.frame(dif = dif)
  tabla <- df %>%
    mutate(is_target = dif == -1,               
           group = cumsum(!is_target)) %>%         
    group_by(group) 
  agrupados <- tabla %>%
    summarise(length = sum(is_target)) %>%         
    filter(length > 0) %>%arrange(desc(length))
  maximo <- agrupados[1,] 
  primerdia <- 0
  for(i in 1:length(tabla$group)){
    if (tabla$group[i]!= maximo$group | tabla$is_target[i] == FALSE){
      next
    } else {
      if (primerdia == 0){
        primerdia <- i
      }
      ultimodia <-i
    }
  }

  maximo <- maximo$length
  primerdia <- num[primerdia]
  ultimodia <- num[ultimodia+1]
  return(list(maximo, primerdia, ultimodia))
}

el_graciosito <- function(df){
  df <- df %>% mutate(sticker = grepl("sticker omitido", df$mensaje))
  df <- df[df$sticker,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

el_grafico <- function(df){
  df <- df %>% mutate(imagen = grepl("imagen omitida", df$mensaje))
  df <- df[df$imagen,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

el_waze <- function(df){
    df <- df %>% mutate(ubicacion = grepl("Ubicación:", df$mensaje))
  df <- df[df$imagen,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

el_inseguro <- function(df){
    df <- df %>% mutate(seguridad = grepl("Cambió tu código de seguridad con", df$mensaje))
  df <- df[df$imagen,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

el_camarografo <- function(df){
    df <- df %>% mutate(video = grepl("Video omitido", df$mensaje))
  df <- df[df$imagen,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

el_wikipedia <- function(df){
    df <- df %>% mutate(docs = grepl("documento omitido", df$mensaje))
  df <- df[df$imagen,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

el_corrector <- function(df){
    df <- df %>% mutate(edit = grepl("<Se editó este mensaje.>", df$mensaje))
  df <- df[df$imagen,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

el_link <- function(df){ # verificar doble
    df <- df %>% mutate(link = grepl("https://", df$mensaje))
  df <- df[df$imagen,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

el_jefe <- function(df){ # verificar doble
    df <- df %>% mutate(ping = grepl("@", df$mensaje))
  df <- df[df$imagen,]
  num <- df %>% count(autor) %>% arrange(desc(n))
  return(num)
}

# imagen omitida
# sticker omitido
# Ubicación:
# https://
# Cambió tu código de seguridad con
# @
# Video omitido
# documento omitido 
# <Se editó este mensaje.>

```

# Funciones para analizar sentimientos en Python
```{python}
'''
Función que analiza sentimientos usando la librería 'nltk'.
Dado que el método utilizado está entrenado en inglés, primero se traducen los
mensajes usando la librería 'translate' (está limitada a una cantidad de traducciones)
'''
import pandas as pd
import time
from nltk.sentiment.vader import SentimentIntensityAnalyzer
#from translate import Translator

# nltk.download('vader_lexicon') # correr solo la primera vez

def sentimientos_nltk(df):
  
  df_pandas = pd.DataFrame(df)
  
  #traductor = Translator(from_lang = 'es', to_lang = 'en')
  
  #df_pandas['mensaje_ingles'] = df_pandas['mensaje'].apply(lambda i: traductor.translate(i)) # traduce los mensajes

  sid = SentimentIntensityAnalyzer()

  df_pandas['sentimiento_nltk'] = df_pandas['mensaje'].apply(lambda j: sid.polarity_scores(j)['compound'])

  #del df_pandas['mensaje_ingles']

  return(df_pandas)


# t = time.time()
# r.gen = sentimientos_nltk(r.gen)
# print(time.time() - t)
```

```{python}
from textblob import TextBlob

def analizar_sentimiento(txt):
  '''
  Función que analiza sentimientos de un texto usando la librería 'TextBlob'.
  '''
  blob = TextBlob(txt)
  sentimiento = blob.sentiment

  return(sentimiento[0])


def sentimientos_textblob(df):
  '''
  Función que analiza sentimientos de una columna de mensajes en un dataframe.
  Este método también está entrenado en inglés, por lo que se utilizan las 
  traducciones previas.
  '''
  
  df_pandas = pd.DataFrame(df)
  df_pandas['sentimiento_textblob'] = df_pandas['mensaje'].apply(lambda j: analizar_sentimiento(j))
  
  return(df_pandas)
  
# t = time.time()
# r.gen = sentimientos_textblob(r.gen)
# print(time.time() - t)
```

```{python}
from transformers import pipeline

def sentimientos_transformers(df):
  '''
  Función que analiza sentimientos usando la librería 'transformers'.
  Este método está entrenado para analizar sentimientos de mensajes en español.
  '''
  
  df_pandas = pd.DataFrame(df)
  sentiment_analysis = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")
  df_pandas['sentimiento_transformers'] = df_pandas['mensaje'].apply(lambda j: sentiment_analysis(j)[0]['score'])
  
  return(df_pandas)

# t = time.time()
# r.gen = sentimientos_transformers(r.gen)
# print(time.time() - t)
```

```{r}
gen_prueba <- gen[1:10,]
```

```{python}
t = time.time()
r.gen_prueba = sentimientos_nltk(r.gen_prueba)
print(time.time() - t)
```

```{python}
t = time.time()
r.gen_prueba = sentimientos_textblob(r.gen_prueba)
print(time.time() - t)
```

```{python}
t = time.time()
r.gen_prueba = sentimientos_transformers(r.gen_prueba)
print(time.time() - t)
```

```{r}
lista <- gen$mensaje
```

|
```{python}
# !pip install deep_translator
from deep_translator import GoogleTranslator
import pandas as pd
import time
traductor = GoogleTranslator(source = 'es', target = 'en')

t = time.time()
fijo = pd.DataFrame(traductor.translate_batch(r.lista))
print(time.time() - t)

resultado["R"] = r.lista
```

```{r}
guardar <- reticulate::py$fijo
write.csv2(guardar, "docs/traducido.csv")
```

```{python}
# import os
# os.getcwdb()
mensajes_traducidos = pd.read_csv('docs/traducido.csv', sep = ';', names = ['id', 'mensaje'])
```

```{python}
df_prueba = mensajes_traducidos.iloc[:100]
#print(df_prueba)

for mensaje in df_prueba['mensaje']:
  print(mensaje, type(mensaje))
```

```{python}
prueba_nltk = sentimientos_textblob(df_prueba)
```




















